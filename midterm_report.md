---
layout: default
title: Midterm Report
---
[< Home](./index.md)

# Midterm Report

### Introduction/Background

The topic that our group will pursue is predicting how many All-Stars an NBA player will obtain over the course of their career, given their statistics during their rookie contract. This could be used by NBA general managers when negotiating contract extensions with NBA players. Most literature in this field predicts the success of NBA players given their college careers through regression analysis. While these papers did not use machine learning, they are useful for feature selection. Potential features include position, draft pick number, minutes played, FT%, assists, steals, blocks, turnovers, personal fouls, and points [<a href="#ref1">1</a>]. Different features could be used depending on whether a player is a guard, forward, or center [<a href="#ref2">2</a>]. We collected data on 245 players drafted between 2005-2020, with the addition of LeBron James, Carmelo Anthony, Kobe Bryant, and Shaquille O'Neal. For each of the 249 players, we collected data on their Years 1-4 games played, games started, MPG, FG%, 3p%, FT%, RPG, APG, SPG, BPG, and PPG. We also determined whether the player was active or not, and counted their number of all-star appearances by their fourth year. We included all 80 players drafted between 2005-2020 with an all-star appearance, the specific players mentioned above, and 165 random players drafted in that time frame.

### Problem Definition

The problem we intend to solve with ML is that many NBA teams struggle and continue to face critical decisions when deciding to build their franchise around their young players. Moreover, while early statistics such as college performance or draft position provide some sort of indication of overall potential, teams continue to struggle with accurately forecasting long term success. Unlike previous literature that have applied a one size fits all approach to player assessment, we intend to tailor predictions through position-based feature weighting (ie. assists would be more impactful for a guard) if their is a correlation, as well as analyze any league-wide trends such as the increased emphasis of three-point shooting and pace of the game. Thus, our model can be represented as much more dynamic and adaptable in comparison to previous static correlations that have been used.

### Methods

First, we implemented data preprocessing methods, found in data_preprocessing.py, to the "NBA ML Dataset - Sheet1.csv" dataset. We used one-hot encoding on the positions played because we wanted to encode the positions numerically, and certain players play multiple positions (for example, Anthony Davis plays PF/C). We also used min-max scaling on the non-percentage data because we wanted all the features to have the same range. That way, stats with a larger range, such as PPG, would not have a higher impact than those with lower ranges, such as BPG or SPG. We used other basic preprocessing strategies in linreg_model.py such as dropping player names and year drafted and replacing the "Yes" and "No" answers of the active column to binary. The processed dataset can be found in the "nba_players_cleaned.csv" file.

After data preprocessing, the next step was to decide which features to train the model on. The processed dataset has over 50 features, which is too many features for the size of the dataset. If we were to train the model on all 50 features, the model would either make poor guesses or completely overfit. Instead, we used the methods in data_visualization.py to determine which features had the strongest correlation with the total number of all-stars throughout a player's career. Particularly interesting is the heatmap generated by feat_correlation_heatmap (shown below) and its numerical results. We found that the 9 most correlated features were "all-stars_by_y4", "y4_ppg", "y3_ppg", "y2_ppg", "y4_spg", "y1_ppg", "y4_mpg", "y3_spg", and "y2_spg". Since some of these features seemed to have a linear correlation with total all stars, we decided to use a linear regression model.

![heat map]({{ site.baseurl }}/assets/images/midterm%20report/Figure_7.png)

Next, we implemented the supervised learning model of linear regression. We split the dataset into two based on whether players had at least one all-star or not, split each into train and test data, and merged them together. That way, the train and test dataset had an equal proportion of good and bad NBA players. After testing, we determined that taking 7% of the data for testing and training on "all-stars_by_y4", "y3_ppg", and "y1_ppg" had the best results. We trained the model accordingly.

### Results and Discussion

In the proposal, we mentioned using F1-scores, which balance precision and recall, making it useful in detecting cases of false positives (wrongly predicting a player will have a certain range of All-Stars) and false negatives (missing a future All-Star). It has also been used as a metric to evaluate ML models in other papers whose goal was to predict NBA players’ performance and popularity [<a href="#ref3">3</a>]. However, we decided to only use MSE and R² to evaluate our model, since we didn't want to make the problem into a categorization one. We used regression planes (fixing each feature in a different graph) to visualize the datapoints and the model's prediction. It fixes one variable, therefore projecting the data into a 3D plot so it can be visualized easier. The model takes the other two features as input, assumes a constant last feature value, and predicts the total number of all-star appearances based off it. Since the slope of the plane fixing Y3 PPG is steep, there is a stronger correlation between the other two features, which can be verified using the heat map. The same applies for fixing Y1 PPG.

![figure 1]({{ site.baseurl }}/assets/images/midterm%20report/Figure_1.png)
![figure 2]({{ site.baseurl }}/assets/images/midterm%20report/Figure_2.png)
![figure 3]({{ site.baseurl }}/assets/images/midterm%20report/Figure_3.png)
![figure 4]({{ site.baseurl }}/assets/images/midterm%20report/Figure_4.png)
![figure 5]({{ site.baseurl }}/assets/images/midterm%20report/Figure_5.png)
![figure 6]({{ site.baseurl }}/assets/images/midterm%20report/Figure_6.png)

When testing the model as described above, we found that it had a MSE value of 2.119 and an R² value of 0.833. This tells us that the linear regression model does a good job predicting how many all-stars an NBA player will have based on their all-star count by year 4, year 3 PPG, and year 1 PPG. An R² value closer to 1 would be more ideal, but for a smaller dataset like ours, this result is very good. The next steps that we plan to take are adding the second and third models, trying to outdo the results of the basic linear regression model.

### Gantt Chart
The Gantt Chart can be accessed [here](https://docs.google.com/spreadsheets/d/10yeWSocKFXN5sgRKlP1bHP6SGMhg_Mfy/edit?usp=sharing&ouid=112407887011389750537&rtpof=true&sd=true)

### Contribution Table

| Name   | Proposal Contributions                                       |
| ------ | ------------------------------------------------------------ |
| Aarav  | Data collection, M1 implementation & coding, midterm report, team coordination |
| Aryan  | Data collection, M1 results evaluation                       |
| Ekechi | Data collection, midterm report                              |
| Jake   | Data collection, M1 data cleaning and preprocessing          |
| Xinyu  | Data collection, data visualization                          |


### References

<div style="padding-left: 2em; text-indent: -2em;">
<p id="ref1">[1] B. Oguntimein and D. Coates, “The Length and Success of NBA Careers: Does College Production Predict Professional Outcomes?,” <i>International Journal of Sport Finance</i>, vol. 5, no. 1, pp. 4–26, 2010.</p>

<p id="ref2">[2] W. Abrams, J. C. Barnes, and A. Clement, “Relationship of selected pre-NBA career variables to NBA players’ career longevity,” <i>The Sport Journal</i>, vol. 11, no. 2, 2008.</p>

<p id="ref3">[3] N. H. Nguyen, D. T. A. Nguyen, B. Ma, and J. Hu, “The application of machine learning and deep learning in sport: predicting NBA players’ performance and popularity,” <i>Journal of Information and Telecommunication</i>, pp. 1–19, Sep. 2021.</p>
</div>