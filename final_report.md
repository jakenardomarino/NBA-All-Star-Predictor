---
layout: default
title: Final Report
---
[< Home](./index.md)

# Final Report

### Introduction/Background

The topic that our group will pursue is predicting how many All-Stars an NBA player will obtain over the course of their career, given their statistics during their rookie contract. This could be used by NBA general managers when negotiating contract extensions with NBA players. Most literature in this field predicts the success of NBA players given their college careers through regression analysis. While these papers did not use machine learning, they are useful for feature selection. Potential features include position, draft pick number, minutes played, FT%, assists, steals, blocks, turnovers, personal fouls, and points [<a href="#ref1">1</a>]. Different features could be used depending on whether a player is a guard, forward, or center [<a href="#ref2">2</a>]. We collected data on 245 players drafted between 2005-2020, with the addition of LeBron James, Carmelo Anthony, Kobe Bryant, and Shaquille O'Neal. For each of the 249 players, we collected data on their Years 1-4 games played, games started, MPG, FG%, 3p%, FT%, RPG, APG, SPG, BPG, and PPG. We also determined whether the player was active or not, and counted their number of all-star appearances by their fourth year. We included all 80 players drafted between 2005-2020 with an all-star appearance, the specific players mentioned above, and 165 random players drafted in that time frame.

### Problem Definition

The problem we intend to solve with ML is that many NBA teams struggle and continue to face critical decisions when deciding to build their franchise around their young players. Moreover, while early statistics such as college performance or draft position provide some sort of indication of overall potential, teams continue to struggle with accurately forecasting long term success. Unlike previous literature that have applied a one size fits all approach to player assessment, we intend to tailor predictions through position-based feature weighting (ie. assists would be more impactful for a guard) if their is a correlation, as well as analyze any league-wide trends such as the increased emphasis of three-point shooting and pace of the game. Thus, our model can be represented as much more dynamic and adaptable in comparison to previous static correlations that have been used.

### Methods

First, we implemented data preprocessing methods, found in data_preprocessing.py, to the "NBA ML Dataset - Sheet1.csv" dataset. We used one-hot encoding on the positions played because we wanted to encode the positions numerically, and certain players play multiple positions (for example, Anthony Davis plays PF/C). We also used min-max scaling on the non-percentage data because we wanted all the features to have the same range. That way, stats with a larger range, such as PPG, would not have a higher impact than those with lower ranges, such as BPG or SPG. We used other basic preprocessing strategies in linreg_model.py such as dropping player names and year drafted and replacing the "Yes" and "No" answers of the active column to binary. The processed dataset can be found in the "nba_players_cleaned.csv" file.

After data preprocessing, the next step was to decide which features to train the model on. The processed dataset has over 50 features, which is too many features for the size of the dataset. If we were to train the model on all 50 features, the model would either make poor guesses or completely overfit. Instead, we used the methods in data_visualization.py to determine which features had the strongest correlation with the total number of all-stars throughout a player's career. Particularly interesting is the heatmap generated by feat_correlation_heatmap (shown below) and its numerical results. We found that the 10 most correlated features were "all-stars_by_y4", "y4_ppg", "y3_ppg", "y2_ppg", "y4_spg", "y1_ppg", "y4_mpg", "y3_spg", "y3_spg", and "y4_spg". Since some of these features seemed to have a linear correlation with total all stars, we decided to use a linear regression model. The heatmap below quantifies the strength of the correlation of these features. Consider either the first row or the first column to see each features' correlation with the total number of all stars.

![heat map]({{ site.baseurl }}/assets/images/midterm%20report/heatmap.png)

In the midterm section of the project, we implemented the supervised learning model of linear regression. We split the dataset into two based on whether players had at least one all-star or not, split each into train and test data, and merged them together. That way, the train and test dataset had an equal proportion of good and bad NBA players. After testing, we determined that taking 7% of the data for testing and training on "all-stars_by_y4", "y3_ppg", and "y1_ppg" had the best results. We trained the model accordingly.

After the midterm, we began working on the other two models. The first of the two was a decision tree regression model. We found through exhaustive search that the same train-test split works best. We used the features "y3_bpg", "y3_ppg", and "y4_gp", since they gave us the best results for our model, and we set the maximum tree depth to be 3. The second of the two new models was a KNN regression model. We used the same train-test split, used the features "all-stars_by_y4", "y4_ppg", "y1_ppg", "y4_mpg", and "y3_mpg", and used the three nearest neighbors. The decision tree model and KNN regression model both worked well for this assignment since they prevent overfitting, especially with the parameters we chose. One danger of using a smaller dataset like ours is that models become prone to overfitting, and using these models helps prevent that.

### Results and Discussion

In the proposal, we mentioned using F1-scores, which balance precision and recall, making it useful in detecting cases of false positives (wrongly predicting a player will have a certain range of All-Stars) and false negatives (missing a future All-Star). It has also been used as a metric to evaluate ML models in other papers whose goal was to predict NBA players’ performance and popularity [<a href="#ref3">3</a>]. However, we decided to only use RMSE and R² to evaluate our model, since we didn't want to make the problem into a categorization one. For the linear regression model, we used regression planes (fixing each feature in a different graph) to visualize the datapoints and the model's prediction. It fixes one variable, therefore projecting the data into a 3D plot so it can be visualized easier. The model takes the other two features as input, assumes a constant last feature value, and predicts the total number of all-star appearances based off it. Since the slope of the plane fixing Y3 PPG is steep, there is a stronger correlation between the other two features, which can be verified using the heat map. The same applies for fixing Y1 PPG.

![figure 1]({{ site.baseurl }}/assets/images/midterm%20report/Figure_1.png)
![figure 2]({{ site.baseurl }}/assets/images/midterm%20report/Figure_2.png)
![figure 3]({{ site.baseurl }}/assets/images/midterm%20report/Figure_3.png)
![figure 4]({{ site.baseurl }}/assets/images/midterm%20report/Figure_4.png)
![figure 5]({{ site.baseurl }}/assets/images/midterm%20report/Figure_5.png)
![figure 6]({{ site.baseurl }}/assets/images/midterm%20report/Figure_6.png)

When testing the linear regression model as described above, we found that it had aRMSE value of 1.456 and an R² value of 0.833. This tells us that the linear regression model does a good job predicting how many all-stars an NBA player will have based on their all-star count by year 4, year 3 PPG, and year 1 PPG. An R² value closer to 1 would be more ideal, but for a smaller dataset like ours, this result is very good. The linear regression model results, calculated in the midterm section of the project, served as a benchmark for improvement for the decision tree and KNN regression models. The decision tree model had a RMSE value of 0.988 and an R² value of 0.923. Below is a visualization of the decision tree used to obtain these results.

![figure 7]({{ site.baseurl }}/visualization/dtreg_tree.png)

![figure 8]({{ site.baseurl }}/visualization/knnreg_residualbar.png)
![figure 9]({{ site.baseurl }}/visualization/knnreg_residualplot.png)
![figure 10]({{ site.baseurl }}/visualization/knnreg_scatterplot.png)

The KNN regression model performed slightly worse than the decision tree model, although it still did better than the linear regression model. The RMSE value we obtained was 1.334, and the R² value was 0.86. Overall, these results were indicative of the success our group had improving the models from the basic linear regression one. Below is a comparison bar graph of the MSE values and R² score between the three models described above.

![figure 11]({{ site.baseurl }}/visualization/comparison.png)

In addition, to compare the three models we used amongst a variety of train-test splits, features, and more, we calculated MSE and R² results over an exhaustive search of each train-test split between 0.05 and 0.20 (0.05, 0.06, ..., 0.20), each non-empty subset of the nine most common features, and having 2-5 neighbors/depth for the KNN and decision tree models, respectively. We found that the model with the best MSE value was Linear Regression 28.9% of the time, Decision Tree 37.7% of the time, and KNN 33.4% of the time. For R² values, the results were similar. Linear Regression had the best R² value 28.6% of the time, while the Decision Tree and KNN models had 37.2% and 34.2% respectively. While certain features favored different models, it was interesting to see that the split of the best model across different features and train-test splits were roughly equal, with Linear Regression being a little less than a third.

![figure 12]({{ site.baseurl }}/visualization/mse_piechart.png)
![figure 13]({{ site.baseurl }}/visualization/r2_piechart.png)

### Gantt Chart
The Gantt Chart can be accessed [here](https://docs.google.com/spreadsheets/d/10yeWSocKFXN5sgRKlP1bHP6SGMhg_Mfy/edit?usp=sharing&ouid=112407887011389750537&rtpof=true&sd=true)

### Contribution Table

| Name   | Final Contributions                                          |
| ------ | ------------------------------------------------------------ |
| Aarav  |  Worked on the presentation, models, GitHub, and report |
| Aryan  |  Worked on the KNN model |
| Ekechi |  Worked on the presentation and report |
| Jake   |  Worked on the decision tree model |
| Xinyu  |  Worked on the KNN model |


### References

<div style="padding-left: 2em; text-indent: -2em;">
<p id="ref1">[1] B. Oguntimein and D. Coates, “The Length and Success of NBA Careers: Does College Production Predict Professional Outcomes?,” <i>International Journal of Sport Finance</i>, vol. 5, no. 1, pp. 4–26, 2010.</p>

<p id="ref2">[2] W. Abrams, J. C. Barnes, and A. Clement, “Relationship of selected pre-NBA career variables to NBA players’ career longevity,” <i>The Sport Journal</i>, vol. 11, no. 2, 2008.</p>

<p id="ref3">[3] N. H. Nguyen, D. T. A. Nguyen, B. Ma, and J. Hu, “The application of machine learning and deep learning in sport: predicting NBA players’ performance and popularity,” <i>Journal of Information and Telecommunication</i>, pp. 1–19, Sep. 2021.</p>
</div>
